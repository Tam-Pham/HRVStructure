---
title: '**Conceptual vs. Observed Structure of Heart Rate Variability (HRV) Indices**'
subtitle: "Data Analysis"
output:
  html_document:
    self_contained: false
    theme: cerulean
    highlight: pygments
    toc: yes
    toc_depth: 3
    toc_float: yes
    number_sections: no
    df_print: default
    code_folding: hide
    code_download: yes
  word_document:
    reference_docx: utils/Template_Word.docx
    highlight: pygments
    toc: no
    toc_depth: 3
    df_print: default
    number_sections: yes
  rmarkdown::html_vignette:
    toc: yes
    toc_depth: 3
  pdf_document:
    toc: yes
    toc_depth: '2'
    latex_engine: xelatex
editor_options:
  chunk_output_type: console
bibliography: utils/bibliography.bib
csl: utils/apa.csl
---


<!-- 
!!!! IMPORTANT: run `source("utils/render.R")` to publish instead of clicking on 'Knit'
-->

```{r setup, warning=FALSE, message=TRUE, include=FALSE}
# Set up the environment (or use local alternative `source("utils/config.R")`)
source("https://raw.githubusercontent.com/RealityBending/TemplateResults/main/utils/config.R")  

fast <- FALSE  # Make this false to skip the chunks

# Set theme
ggplot2::theme_set(see::theme_modern())

source_rmd <- function(x){
  file <- knitr::purl(x, quiet=TRUE)
  source(file)
  if (file.exists(file)) file.remove(file)
}
```

# Introduction
```{r badges, echo=FALSE, message=TRUE, warning=FALSE, results='asis'}
# This chunk is a bit complex so don't worry about it: it's made to add badges to the HTML versions
# NOTE: You have to replace the links accordingly to have working "buttons" on the HTML versions
if (!knitr::is_latex_output() && knitr::is_html_output()) {
  cat("![Build](https://github.com/Tam-Pham/HRVStructure/workflows/Build/badge.svg)
      [![Website](https://img.shields.io/badge/repo-Readme-2196F3)](https://github.com/Tam-Pham/HRVStructure)
      [![Website](https://img.shields.io/badge/visit-website-E91E63)](https://realitybending.github.io/TemplateResults/)
      [![Website](https://img.shields.io/badge/download-.docx-FF5722)](https://github.com/RealityBending/TemplateResults/raw/main/word_and_pdf/SupplementaryMaterials.docx)
      [![Website](https://img.shields.io/badge/see-.pdf-FF9800)](https://github.com/RealityBending/TemplateResults/blob/main/word_and_pdf/SupplementaryMaterials.pdf)")
}
```



The aim of this study is to explore the factor structure of HRV indices.

# Methods


## Databases

### Glasgow University Database

The GUDB Database [@howell2018high] contains ECGs from 25 subjects. Each subject was recorded performing 5 different tasks for two minutes (sitting, doing a maths test on a tablet, walking on a treadmill, running on a treadmill, using a hand bike). The sampling rate is 250Hz for all the conditions.

The script to download and format the database using the [**ECG-GUDB**](https://github.com/berndporr/ECG-GUDB) Python package by Bernd Porr can be found [**here**](https://github.com/neuropsychology/NeuroKit/blob/dev/data/gudb/download_gudb.py).

### MIT-BIH Arrhythmia Database

The MIT-BIH Arrhythmia Database [MIT-Arrhythmia; @moody2001impact] contains 48 excerpts of 30-min of two-channel ambulatory ECG recordings sampled at 360Hz and 25 additional recordings from the same participants including common but clinically significant arrhythmias (denoted as the `MIT-Arrhythmia-x` database).

The script to download and format the database using the can be found [**here**](https://github.com/neuropsychology/NeuroKit/blob/dev/data/mit_arrhythmia/download_mit_arrhythmia.py).


### MIT-BIH Normal Sinus Rhythm Database

This database includes 18 clean long-term ECG recordings of subjects. Due to memory limits, we only kept the second hour of recording of each participant.

The script to download and format the database using the can be found [**here**](https://github.com/neuropsychology/NeuroKit/blob/dev/data/mit_normal/download_mit_normal.py).


<!-- ### Lobachevsky University Electrocardiography Database -->

<!-- The Lobachevsky University Electrocardiography Database [LUDB; @kalyakulina2018lu] consists of 200 10-second 12-lead ECG signal records representing different morphologies of the ECG signal. The ECGs were collected from healthy volunteers and patients, which had various cardiovascular diseases. The boundaries of P, T waves and QRS complexes were manually annotated by cardiologists for all 200 records. -->

### Fantasia Database

The Fantasia database [@iyengar1996age] consists of twenty young and twenty elderly healthy subjects. All subjects remained in a resting state in sinus rhythm while watching the movie Fantasia (Disney, 1940) to help maintain wakefulness. The continuous ECG signals were digitized at 250 Hz. Each heartbeat was annotated using an automated arrhythmia detection algorithm, and each beat annotation was verified by visual inspection.




## Procedure

```{python, eval=FALSE, echo=FALSE}
import pandas as pd
import numpy as np
import neurokit2 as nk

# Load True R-peaks location
datafiles = [pd.read_csv("../../data/gudb/Rpeaks.csv"),
             pd.read_csv("../../data/mit_arrhythmia/Rpeaks.csv"),
             pd.read_csv("../../data/mit_normal/Rpeaks.csv"),
             pd.read_csv("../../data/fantasia/Rpeaks.csv")]

# Get results
all_results = pd.DataFrame()

for file in datafiles:
    for database in np.unique(file["Database"]):
        data = file[file["Database"] == database]
        for participant in np.unique(data["Participant"]):
            data_participant = data[data["Participant"] == participant]
            sampling_rate = np.unique(data_participant["Sampling_Rate"])[0]
            rpeaks = data_participant["Rpeaks"].values

            results = nk.hrv(rpeaks, sampling_rate=sampling_rate)
            results["Participant"] = participant
            results["Database"] = database
            results["Recording_Length"] = rpeaks[-1] / sampling_rate / 60

            all_results = pd.concat([all_results, results], axis=0)

all_results.to_csv("data/data.csv", index=False)
```

# Results

```{r, message=FALSE, warning=FALSE, results='hide'}
library(tidyverse)
library(easystats)

data <- read.csv("data/data.csv", stringsAsFactors = FALSE) %>% 
  select(-HRV_ULF, -HRV_VLF) %>%  # Empty
  # filter(Database != "LUDB") %>% # too short recordings, many indices didn't converge
  setNames(stringr::str_remove(names(.), "HRV_")) %>% 
  mutate_all(function(x) {
    x[is.infinite(x)] <- NA
    return(x) })
```


```{r warning=FALSE, message=TRUE, results='asis'}
cat("This study includes", 
    nrow(data), 
    "participants from", 
    length(unique(data$Database)), 
    "databases.")
```


```{r convenience_chunk_for_local_running, include = FALSE, eval = FALSE}
library(patchwork)
library(tidyverse)
library(easystats)

# # To run things locally: CTRL + ALT + SHIFT + P, and then the next two lines
source_rmd("0_ConvenienceFunctions.Rmd")
source_rmd("1_Preprocessing.Rmd")
source_rmd("3_Dimensions.Rmd")
# # source_rmd("5_BehaviouralModels.Rmd")
# 
# chains <- 5
# iter <- 5000
# 
# find_cache <- function(pattern = "") {
#   files <- paste0("index_cache/html/", list.files("index_cache/html/", pattern = "\\.rdx$"))
#   files <- files[stringr::str_detect(files, pattern)]
#   stringr::str_remove(files, ".rdx")
# }
# 
# lapply(find_cache(), lazyLoad, environment())
# 
# lapply(find_cache("index_cache/html/model_baseline_PS_RT"), lazyLoad, environment())
# lapply(find_cache("index_cache/html/model_baseline_RS_RT"), lazyLoad, environment())
# lapply(find_cache("index_cache/html/model_baseline_RI_RT"), lazyLoad, environment())
# lapply(find_cache("index_cache/html/model_baseline_RI_Err"), lazyLoad, environment())
# lapply(find_cache("index_cache/html/model_baseline_CR_RT"), lazyLoad, environment())
# lapply(find_cache("index_cache/html/model_baseline_CR_Err"), lazyLoad, environment())
```



## Preprocessing

```{r child='0_ConvenienceFunctions.Rmd'}
```


```{r child='1_Preprocessing.Rmd'}
```

## Effect of Recording Length

```{r child='2_RecordingLength.Rmd'}
```


## Dimensional Structure

```{r child='3_Dimensions.Rmd'}
```

<!-- ### Gaussian Graphical Model -->


<!-- ```{r, message=FALSE, warning=FALSE, fig.width=17, fig.height=17} -->
<!-- library(ggraph) -->

<!-- data %>%  -->
<!--   correlation::correlation(partial=FALSE) %>%  -->
<!--   correlation::cor_to_pcor() %>%  -->
<!--   filter(abs(r) > 0.2) %>% -->
<!--   tidygraph::as_tbl_graph(directed=FALSE) %>%  -->
<!--   dplyr::mutate(closeness = tidygraph::centrality_closeness(normalized = TRUE), -->
<!--                 degree = tidygraph::centrality_degree(normalized = TRUE), -->
<!--                 betweeness = tidygraph::centrality_betweenness(normalized = TRUE)) %>% -->
<!--   tidygraph::activate(nodes) %>% -->
<!--   dplyr::mutate(group1 = as.factor(tidygraph::group_edge_betweenness()), -->
<!--                 # group2 = as.factor(tidygraph::group_optimal()), -->
<!--                 # group3 = as.factor(tidygraph::group_walktrap()), -->
<!--                 # group4 = as.factor(tidygraph::group_spinglass()), -->
<!--                 group5 = as.factor(tidygraph::group_louvain())) %>%  -->
<!--   ggraph::ggraph(layout = "fr") + -->
<!--     ggraph::geom_edge_arc(aes(colour = r, edge_width = abs(r)), strength = 0.1, show.legend = FALSE) + -->
<!--     ggraph::geom_node_point(aes(size = degree, color = group5), show.legend = FALSE) + -->
<!--     ggraph::geom_node_text(aes(label = name), colour = "white") + -->
<!--     ggraph::scale_edge_color_gradient2(low = "#a20025", high = "#008a00", name = "r") + -->
<!--     ggraph::theme_graph() + -->
<!--     guides(edge_width = FALSE) + -->
<!--     scale_x_continuous(expand = expansion(c(.10, .10))) + -->
<!--     scale_y_continuous(expand = expansion(c(.10, .10))) + -->
<!--     scale_size_continuous(range = c(20, 30)) + -->
<!--     scale_edge_width_continuous(range = c(0.5, 2)) + -->
<!--     see::scale_color_material_d(palette="rainbow", reverse=TRUE) -->
<!-- ``` -->

<!-- Groups were identified using the [tidygraph::group_optimal](https://rdrr.io/cran/tidygraph/man/group_graph.html) algorithm. -->




<!-- ### Cluster Analysis -->

<!-- #### How many clusters -->

<!-- ```{r, message=FALSE, warning=FALSE} -->
<!-- dat <- effectsize::standardize(data[sapply(data, is.numeric)]) -->

<!-- n <- parameters::n_clusters(t(dat), package = c("mclust", "cluster")) -->

<!-- n -->

<!-- plot(n) + -->
<!--   theme_modern() -->
<!-- ``` -->


<!-- ```{r, message=FALSE, warning=FALSE, fig.width=7, fig.height=10} -->
<!-- library(dendextend) -->

<!-- dat <- effectsize::standardize(data[sapply(data, is.numeric)]) -->

<!-- result <- pvclust::pvclust(dat, method.dist="euclidean", method.hclust="ward.D2", nboot=10, quiet=TRUE) -->

<!-- result %>%  -->
<!--   as.dendrogram() %>%  -->
<!--   sort() %>%  -->
<!--   dendextend::pvclust_show_signif_gradient(result, signif_col_fun = grDevices::colorRampPalette(c("black", "red"))) %>%  -->
<!--   dendextend::pvclust_show_signif(result, signif_value = c(2, 1)) %>% -->
<!--   dendextend::as.ggdend() %>%  -->
<!--   ggplot2::ggplot(horiz=TRUE, offset_labels = -1) -->
<!-- ``` -->



## References
