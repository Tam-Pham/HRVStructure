---
output: html_document
editor_options: 
  chunk_output_type: console
---


### Clustering
Clustering is the process of assigning data to different groupings according to their similarity. Each approach under the clustering group will have different set of criteria to determine the association between data points. However, they rely on the same set of distance and linkage methods where the formal determines how the distance (similarity) between two points are calculated and the later determines how inter-cluster distance can be derived. 

In this paper, two non-hierarchical clustering methods employed are k-means and k-medoids in which data points are partitioned into *k* sets (clusters). The optimal *k* value is determined by the `n_factor` function from the *parameters* package where the solution with the maximum consensus of a large number of methods is chosen as the final outcome. The hierarchical clustering relied on *euclidean* distance method (shortest distance between two data points) and *average* linkage method (average of all inter-cluster's distances while compensating for the number of points in each cluster) to partition the data into clusters. 

For the density-based clustering, the *epsilon* value (maximum distance between two points to be in assigned to the same cluster) in DBSCAN clustering is determined by the `n_clusters_dbscan` function in *parameters* package. The minimum number of points of a cluster is set to 2 for both DBSCAN and HDBSCAN.

Last but not least, the model-based clustering, based on finite Gaussian mixture modelling, was applied to the dataset to estimate the probability of each data being assigned to different cluster solutions. An advantage of this method is that it automatically identifies the optimal number of clusters and thus no parameters were required as pre-requisites. 


```{r, message=FALSE, warning=FALSE}
# Preprocessing
z <- effectsize::standardize(data[hrv_cols])
z <- datawizard::data_transpose(z)
z <- z[ , colSums(is.na(z)) < 0.2 * nrow(z)]  # keep only participants with few nans
z[is.na(z)] <- 0  # mean imputation
```


#### K-Means

##### How Many Clusters

```{r, message=FALSE, warning=FALSE}
set.seed(3)

n <- parameters::n_clusters(z, 
                            standardize = FALSE, 
                            package = "all", 
                            nbclust_method = "average",
                            fast = FALSE)

n

plot(n)
```

##### 2-K Solution

```{r, message=FALSE, warning=FALSE, fig.cap="K-Means 2-cluster Clustegram solution"}
set.seed(3)

rez <- parameters::cluster_analysis(z, standardize = FALSE, n = 2, method = "hkmeans")

as.data.frame(rez)[1:3]

insight::display(parameters::cluster_performance(rez))

plot(rez)

table_clusters <- assign_clusters(table_clusters, z, clusters = as.character(predict(rez)), col = "Kmeans_2")
```

##### 7-K Solution

```{r, message=FALSE, warning=FALSE, fig.cap="K-Means 7-cluster Clustegram solution"}
set.seed(3)

rez <- parameters::cluster_analysis(z, standardize = FALSE, n = 7, method = "hkmeans")

as.data.frame(rez)[1:3]

insight::display(parameters::cluster_performance(rez))

plot(rez)


table_clusters <- assign_clusters(table_clusters, z, clusters = as.character(predict(rez)), col = "Kmeans_7")
```

##### 10-K Solution

```{r, message=FALSE, warning=FALSE, fig.cap="K-Means 10-cluster Clustegram solution"}
set.seed(3)

rez <- parameters::cluster_analysis(z, n = 10, method = "hkmeans")

as.data.frame(rez)[1:3]

insight::display(parameters::cluster_performance(rez))

plot(rez)

table_clusters <- assign_clusters(table_clusters, z, clusters = as.character(predict(rez)), col = "Kmeans_10")
```


#### K-meloid
```{r, message=FALSE, warning=FALSE, cache = TRUE, fig.cap="K-Meloid 3-cluster Clustegram solution"}
set.seed(3)

rez <- parameters::cluster_analysis(z, method = "pamk", distance_method = "euclidean")

as.data.frame(rez)[1:3]

insight::display(parameters::cluster_performance(rez))

plot(rez)

table_clusters <- assign_clusters(table_clusters, z, clusters = as.character(predict(rez)), col = "Kmeloid")
```

#### Hierarchical Clustering

##### Clustering (95\%)

```{r, message=FALSE, warning=FALSE, cache = TRUE, fig.cap="Hierarchical Clustering 11-cluster dendogram solution"}
set.seed(3)

rez <- parameters::cluster_analysis(z, n = NULL, standardize = FALSE, method = "hclust", distance_method = "euclidean", hclust_method = "average", ci = 0.95, iterations = 2000)

as.data.frame(rez)[1:3]

insight::display(parameters::cluster_performance(rez))

plot(rez)

table_clusters <- assign_clusters(table_clusters, z, clusters = as.character(predict(rez)), col = "Hclust_95")
```



```{r, message=FALSE, warning=FALSE}
clusters <- table_clusters$Hclust_95
names(clusters) <- table_clusters$Index

library(ggraph)
plot_dendrogram(model = attributes(rez)$model$hclust, clusters = clusters, ylim = -10, nudge_y = -0.05, angle = 90)
```

##### Clustering (90\%)

```{r, message=FALSE, warning=FALSE, cache = TRUE, fig.cap="Hierarchical Clustering 13-cluster dendogram solution"}
set.seed(3)

rez <- parameters::cluster_analysis(z, n = NULL, standardize = FALSE, method = "hclust", distance_method = "euclidean", hclust_method = "average", ci = 0.90, iterations = 2000)

as.data.frame(rez)[1:3]

insight::display(parameters::cluster_performance(rez))

plot(rez)

table_clusters <- assign_clusters(table_clusters, z, clusters = as.character(predict(rez)), col = "Hclust_90")
```



```{r, message=FALSE, warning=FALSE}
clusters <- table_clusters$Hclust_90
names(clusters) <- table_clusters$Index

plot_dendrogram(model = attributes(rez)$model$hclust, clusters = clusters, ylim = -10, nudge_y = -0.05, angle = 90,)
```

#### DBSCAN

##### Parameters Selection

```{r, message=FALSE, warning=FALSE}
n <- n_clusters_dbscan(z, standardize = FALSE, eps_range = c(0.1, 30), min_size = 2, method = "kNN")
plot(n)
```

##### DBSCAN

```{r, message=FALSE, warning=FALSE, fig.cap="DBSCAN 6-cluster clustergram solution"}
rez <- parameters::cluster_analysis(z, n = NULL, standardize = FALSE, method = "dbscan", dbscan_eps = 10, min_size = 2, borderPoints = TRUE)

as.data.frame(rez)[1:3]

insight::display(parameters::cluster_performance(rez))

plot(rez)

table_clusters <- assign_clusters(table_clusters, z, clusters = as.character(predict(rez)), col = "DBSCAN")
```

##### HDBSCAN

```{r, message=FALSE, warning=FALSE, fig.cap="HDBSCAN 13-cluster clustergram solution"}
rez <- parameters::cluster_analysis(z, n = NULL, standardize = FALSE, method = "hdbscan", min_size = 2)

as.data.frame(rez)[1:3]

insight::display(parameters::cluster_performance(rez))

plot(rez)

table_clusters <- assign_clusters(table_clusters, z, clusters = as.character(predict(rez)), col = "HDBSCAN")
```

#### Mixture Modelling


```{r, message=FALSE, warning=FALSE, fig.cap="Mixture Modelling 6-cluster clustergram solution"}
suppressMessages(library(mclust))
library(mclust)
rez <- parameters::cluster_analysis(z, method = "mixture")

as.data.frame(rez)[1:3]

insight::display(parameters::cluster_performance(rez))

plot(rez)


table_clusters <- assign_clusters(table_clusters, z, clusters = as.character(predict(rez)), col = "Mixture")
```
